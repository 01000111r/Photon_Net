{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photonic Classifier Smoke Tests\n",
    "\n",
    "This notebook contains a series of \"smoke tests\" for the `p_pack` module. The purpose is to provide a quick way to run basic checks on individual functions during development.\n",
    "\n",
    "**How to use this notebook:**\n",
    "1.  Use `Ctrl+F` or `Cmd+F` to find the function you are working on.\n",
    "2.  Run the test cell for that function to see if it passes.\n",
    "3.  The cell immediately below the test will display the source code of the function being tested, allowing you to compare the test with the implementation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import unittest\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import inspect\n",
    "from p_pack import globals, circ, loss, model, optimiser, pre_p, train\n",
    "\n",
    "# Import all the modules from the package\n",
    "# Assuming 'p_pack' is a valid package in your environment\n",
    "# from p_pack import circ, globals, loss, model, optimiser, pre_p, train\n",
    "\n",
    "# Helper function to display the source code of a function\n",
    "def show_code(func):\n",
    "    \"\"\"\n",
    "    Displays the source code of a given function.\n",
    "    Handles regular and JIT-compiled functions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        source_lines, _ = inspect.getsourcelines(func)\n",
    "        print(\"Source Code:\")\n",
    "        # Corrected line: Use an empty string \"\" to join the source lines.\n",
    "        print(\"\".join(source_lines))\n",
    "    except TypeError as e:\n",
    "        print(f\"Could not get source for {func}: {e}\")\n",
    "        print(\"This can happen with JIT-compiled functions. Showing the .py_func attribute if available.\")\n",
    "        if hasattr(func, 'py_func'):\n",
    "            source_lines, _ = inspect.getsourcelines(func.py_func)\n",
    "            print(\"Source Code (from .py_func):\")\n",
    "            # Corrected line: Same fix as above.\n",
    "            print(\"\".join(source_lines))\n",
    "\n",
    "# This function will run a single test case\n",
    "def run_test(test_class, test_name):\n",
    "    \"\"\"\n",
    "    Creates a test suite for a single test case and runs it.\n",
    "    \"\"\"\n",
    "    suite = unittest.TestSuite()\n",
    "    suite.addTest(test_class(test_name))\n",
    "    runner = unittest.TextTestRunner()\n",
    "    print(f\"--- Running test: {test_name} ---\")\n",
    "    result = runner.run(suite)\n",
    "    if not result.wasSuccessful():\n",
    "        print(f\"--- Test Failed: {test_name} ---\")\n",
    "    else:\n",
    "        print(f\"--- Test Passed: {test_name} ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Module: `p_pack.circ`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `initialize_phases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestInitializePhases(unittest.TestCase):\n",
    "    def test_shape(self):\n",
    "        \"\"\"Test the phase initialization function.\"\"\"\n",
    "        depth, width = 5, 8\n",
    "        phases = circ.initialize_phases(depth, width)\n",
    "        self.assertEqual(phases.shape, (depth, width // 2, 2))\n",
    "\n",
    "run_test(TestInitializePhases, 'test_shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(circ.initialize_phases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `layer_unitary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.007s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_unitarity ---\n",
      "--- Test Passed: test_unitarity ---\n"
     ]
    }
   ],
   "source": [
    "class TestLayerUnitary(unittest.TestCase):\n",
    "    def test_unitarity(self):\n",
    "        \"\"\"Test the layer unitary creation and check for unitarity.\"\"\"\n",
    "        depth, width = 5, 8\n",
    "        all_phases = circ.initialize_phases(depth, width)\n",
    "        layer_idx = 2\n",
    "        \n",
    "        # FIX: The math in the original layer_unitary was incorrect.\n",
    "        # The function has been corrected in the source file to use a standard\n",
    "        # unitary beamsplitter parameterization.\n",
    "        unitary = circ.layer_unitary(all_phases, layer_idx)\n",
    "        self.assertEqual(unitary.shape, (width, width))\n",
    "        \n",
    "        identity = jnp.eye(width, dtype=jnp.complex64)\n",
    "        product = unitary @ unitary.T.conj()\n",
    "        self.assertTrue(jnp.allclose(product, identity, atol=1e-6))\n",
    "\n",
    "run_test(TestLayerUnitary, 'test_unitarity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(circ.layer_unitary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `data_upload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.057s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shape ---\n",
      "--- Test Passed: test_shape ---\n"
     ]
    }
   ],
   "source": [
    "class TestDataUpload(unittest.TestCase):\n",
    "    def test_shape(self):\n",
    "        \"\"\"Test the data upload mechanism.\"\"\"\n",
    "        num_samples, feature_dim = 10, 4\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        unitary = circ.data_upload(data_set)\n",
    "        self.assertEqual(unitary.shape, (num_samples, feature_dim * 2, feature_dim * 2))\n",
    "\n",
    "run_test(TestDataUpload, 'test_shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(circ.data_upload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `measurement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shapes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.272s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Passed: test_shapes ---\n"
     ]
    }
   ],
   "source": [
    "class TestMeasurement(unittest.TestCase):\n",
    "    def test_shapes(self):\n",
    "        \"\"\"Test the measurement function.\"\"\"\n",
    "        num_samples, num_modes = 10, globals.num_modes_circ\n",
    "        dummy_unitaries = jnp.array([jnp.eye(num_modes, dtype=jnp.complex64)] * num_samples)\n",
    "        \n",
    "        sub_unitaries, combos, probs, binary_probs = circ.measurement(dummy_unitaries)\n",
    "\n",
    "        self.assertIsNotNone(sub_unitaries)\n",
    "        self.assertIsNotNone(combos)\n",
    "        self.assertEqual(probs.shape[0], num_samples)\n",
    "        self.assertEqual(binary_probs.shape, (num_samples, 1))\n",
    "\n",
    "run_test(TestMeasurement, 'test_shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(circ.measurement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.pre_p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `rescale_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.035s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_scaling ---\n",
      "--- Test Passed: test_scaling ---\n"
     ]
    }
   ],
   "source": [
    "class TestRescaleData(unittest.TestCase):\n",
    "    def test_scaling(self):\n",
    "        \"\"\"Test the data rescaling function.\"\"\"\n",
    "        data = jnp.array([-10., 0., 10.])\n",
    "        min_val, max_val = -np.pi / 2, np.pi / 2\n",
    "        rescaled = pre_p.rescale_data(data, min_val, max_val)\n",
    "        \n",
    "        self.assertTrue(jnp.all(rescaled >= min_val))\n",
    "        self.assertTrue(jnp.all(rescaled <= max_val))\n",
    "\n",
    "run_test(TestRescaleData, 'test_scaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(pre_p.rescale_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `load_mnist_35`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_loading (__main__.TestLoadMnist.test_loading)\n",
      "Test loading data from a CSV file.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/7v/6bnphj4937q9tbp6zlbd71pr0000gn/T/ipykernel_8293/1892411339.py\", line 20, in test_loading\n",
      "    self.assertEqual(X.shape, (5, self.feature_dim))\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: Tuples differ: (4, 4) != (5, 4)\n",
      "\n",
      "First differing element 0:\n",
      "4\n",
      "5\n",
      "\n",
      "- (4, 4)\n",
      "?  ^\n",
      "\n",
      "+ (5, 4)\n",
      "?  ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.114s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_loading ---\n",
      "--- Test Failed: test_loading ---\n"
     ]
    }
   ],
   "source": [
    "class TestLoadMnist(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Create a dummy CSV file for testing.\"\"\"\n",
    "        self.test_dir = \"test_data_temp\"\n",
    "        os.makedirs(self.test_dir, exist_ok=True)\n",
    "        self.feature_dim = 4\n",
    "        self.fname = f\"mnist_3-5_{self.feature_dim}d_train.csv\"\n",
    "        self.path = os.path.join(self.test_dir, self.fname)\n",
    "        data = np.random.rand(5, self.feature_dim + 1)\n",
    "        pd.DataFrame(data).to_csv(self.path, index=False, header=False)\n",
    "\n",
    "    def tearDown(self):\n",
    "        \"\"\"Remove the dummy CSV and directory.\"\"\"\n",
    "        os.remove(self.path)\n",
    "        os.rmdir(self.test_dir)\n",
    "\n",
    "    def test_loading(self):\n",
    "        \"\"\"Test loading data from a CSV file.\"\"\"\n",
    "        X, y = pre_p.load_mnist_35(self.test_dir, self.feature_dim, split=\"train\")\n",
    "        self.assertEqual(X.shape, (5, self.feature_dim))\n",
    "        self.assertEqual(y.shape, (5,))\n",
    "\n",
    "run_test(TestLoadMnist, 'test_loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(pre_p.load_mnist_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `full_unitaries_data_reupload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running test: test_shapes ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_shapes (__main__.TestFullUnitaries.test_shapes)\n",
      "Test the function that builds the full unitary for the model.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 174, in _broadcast_shapes_uncached\n",
      "    return _try_broadcast_shapes(*rank_promoted_shapes, name='broadcast_shapes')\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 128, in _try_broadcast_shapes\n",
      "    raise TypeError(f'{name} got incompatible shapes for broadcasting: '\n",
      "                    f'{\", \".join(map(str, map(tuple, shapes)))}.')\n",
      "TypeError: broadcast_shapes got incompatible shapes for broadcasting: (10, 512), (1, 216).\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 152, in broadcast_shapes\n",
      "    return _broadcast_shapes_cached(*shapes)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/util.py\", line 302, in wrapper\n",
      "    return cached(config.trace_context() if trace_context_in_key else _ignore(),\n",
      "                  *args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/util.py\", line 296, in cached\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 158, in _broadcast_shapes_cached\n",
      "    return _broadcast_shapes_uncached(*shapes)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 177, in _broadcast_shapes_uncached\n",
      "    raise ValueError(f\"Incompatible shapes for broadcasting: shapes={list(shapes)}\") from err\n",
      "ValueError: Incompatible shapes for broadcasting: shapes=[(10, 512), (216,)]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 174, in _broadcast_shapes_uncached\n",
      "    return _try_broadcast_shapes(*rank_promoted_shapes, name='broadcast_shapes')\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 128, in _try_broadcast_shapes\n",
      "    raise TypeError(f'{name} got incompatible shapes for broadcasting: '\n",
      "                    f'{\", \".join(map(str, map(tuple, shapes)))}.')\n",
      "TypeError: broadcast_shapes got incompatible shapes for broadcasting: (10, 512), (1, 216).\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/7v/6bnphj4937q9tbp6zlbd71pr0000gn/T/ipykernel_8293/2581610446.py\", line 11, in test_shapes\n",
      "    outputs = model.full_unitaries_data_reupload(phases, data_set, weights)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/p_pack/model.py\", line 65, in full_unitaries_data_reupload\n",
      "    sub_unitaries, _, label_probs, binary_probs_plus = circ.measurement(unitaries, num_photons = 3)\n",
      "                                                       ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/p_pack/circ.py\", line 339, in measurement\n",
      "    all_probs = all_probs0 / factorials  # Broadcasting over columns\n",
      "                ~~~~~~~~~~~^~~~~~~~~~~~\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/array_methods.py\", line 573, in deferring_binary_op\n",
      "    return binary_op(*args)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/traceback_util.py\", line 180, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 337, in cache_miss\n",
      "    pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)\n",
      "                     ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 177, in _python_pjit_helper\n",
      "    p, args_flat = _infer_params(fun, jit_info, args, kwargs)\n",
      "                   ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 769, in _infer_params\n",
      "    p, args_flat = _infer_params_impl(\n",
      "                   ~~~~~~~~~~~~~~~~~~^\n",
      "        fun, ji, pjit_mesh, resource_env, args, kwargs, in_avals=avals)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 651, in _infer_params_impl\n",
      "    jaxpr, consts, out_avals, attrs_tracked = _create_pjit_jaxpr(\n",
      "                                              ~~~~~~~~~~~~~~~~~~^\n",
      "        flat_fun, in_type, attr_token, dbg,\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        HashableFunction(res_paths, closure=()),\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        IgnoreKey(ji.inline))\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 335, in memoized_fun\n",
      "    ans = call(fun, *args)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/pjit.py\", line 1315, in _create_pjit_jaxpr\n",
      "    jaxpr, global_out_avals, consts, attrs_tracked = pe.trace_to_jaxpr_dynamic(\n",
      "                                                     ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        fun, in_type, debug_info=pe_debug)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/profiler.py\", line 333, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/interpreters/partial_eval.py\", line 2189, in trace_to_jaxpr_dynamic\n",
      "    ans = fun.call_wrapped(*in_tracers)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/linear_util.py\", line 187, in call_wrapped\n",
      "    return self.f_transformed(*args, **kwargs)\n",
      "           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 294, in _argnums_partial\n",
      "    return _fun(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 74, in flatten_fun\n",
      "    ans = f(*py_args, **py_kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/api_util.py\", line 691, in result_paths\n",
      "    ans = _fun(*args, **kwargs)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/ufuncs.py\", line 2445, in true_divide\n",
      "    x1, x2 = promote_args_inexact(\"true_divide\", x1, x2)\n",
      "             ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/util.py\", line 211, in promote_args_inexact\n",
      "    return promote_shapes(fun_name, *promote_dtypes_inexact(*args))\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/numpy/util.py\", line 59, in promote_shapes\n",
      "    result_rank = len(lax.broadcast_shapes(*shapes))\n",
      "                      ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 154, in broadcast_shapes\n",
      "    return _broadcast_shapes_uncached(*shapes)\n",
      "  File \"/Users/giancarloramirez/Documents/qml_project/venv/lib/python3.13/site-packages/jax/_src/lax/lax.py\", line 177, in _broadcast_shapes_uncached\n",
      "    raise ValueError(f\"Incompatible shapes for broadcasting: shapes={list(shapes)}\") from err\n",
      "ValueError: Incompatible shapes for broadcasting: shapes=[(10, 512), (216,)]\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2.765s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test Failed: test_shapes ---\n"
     ]
    }
   ],
   "source": [
    "class TestFullUnitaries(unittest.TestCase):\n",
    "    def test_shapes(self):\n",
    "        \"\"\"Test the function that builds the full unitary for the model.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "\n",
    "        # FIX: The original model.py was missing imports and had NameErrors.\n",
    "        # The source file has been corrected to properly import from circ.\n",
    "        outputs = model.full_unitaries_data_reupload(phases, data_set, weights)\n",
    "        \n",
    "        self.assertEqual(len(outputs), 4)\n",
    "        unitaries, sub_unitaries, label_probs, binary_probs_plus = outputs\n",
    "        self.assertEqual(unitaries.shape[0], num_samples)\n",
    "        self.assertIsNotNone(sub_unitaries)\n",
    "        self.assertEqual(label_probs.shape[0], num_samples)\n",
    "        self.assertEqual(binary_probs_plus.shape, (num_samples, 1))\n",
    "\n",
    "run_test(TestFullUnitaries, 'test_shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(model.full_unitaries_data_reupload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `predict_reupload`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPredictReupload(unittest.TestCase):\n",
    "    def test_shapes(self):\n",
    "        \"\"\"Test the prediction function.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "\n",
    "        probs, adjusted_binary_probs = model.predict_reupload(phases, data_set, weights)\n",
    "\n",
    "        self.assertEqual(probs.shape[0], num_samples)\n",
    "        self.assertEqual(adjusted_binary_probs.shape, (num_samples, 1))\n",
    "\n",
    "run_test(TestPredictReupload, 'test_shapes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(model.predict_reupload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.loss`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoss(unittest.TestCase):\n",
    "    def test_calculation(self):\n",
    "        \"\"\"Test the loss function returns a scalar value.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        labels = jnp.ones(num_samples)\n",
    "\n",
    "        # FIX: The original loss.py had a NameError.\n",
    "        # The source file is corrected to call model.predict_reupload.\n",
    "        loss_value = loss.loss(phases, data_set, labels, weights)\n",
    "        self.assertTrue(jnp.isscalar(loss_value))\n",
    "\n",
    "run_test(TestLoss, 'test_calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(loss.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.optimiser`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `adam_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestAdamStep(unittest.TestCase):\n",
    "    def test_step(self):\n",
    "        \"\"\"Test a single step of the Adam optimizer.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        params_phases = circ.initialize_phases(depth, width=feature_dim * 2)\n",
    "        params_weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        labels = jnp.ones(num_samples)\n",
    "        m_phases = jnp.zeros_like(params_phases)\n",
    "        v_phases = jnp.zeros_like(params_phases)\n",
    "        m_weights = jnp.zeros_like(params_weights)\n",
    "        v_weights = jnp.zeros_like(params_weights)\n",
    "\n",
    "        carry = [params_phases, data_set, labels, params_weights, m_phases, v_phases, m_weights, v_weights]\n",
    "        step_number = 1\n",
    "\n",
    "        # FIX: The original optimiser.py had a TypeError, calling the loss module.\n",
    "        # The source file is corrected to call loss.loss().\n",
    "        new_carry, loss_info = optimiser.adam_step(carry, step_number)\n",
    "\n",
    "        self.assertEqual(len(new_carry), 8)\n",
    "        self.assertEqual(loss_info.shape, (2,))\n",
    "\n",
    "run_test(TestAdamStep, 'test_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(optimiser.adam_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module: `p_pack.train`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTrain(unittest.TestCase):\n",
    "    def test_train_run(self):\n",
    "        \"\"\"Test the main training function.\"\"\"\n",
    "        depth, feature_dim, num_samples = 5, 4, 10\n",
    "        phases = circ.initialize_phases(depth, width=feature_dim*2)\n",
    "        weights = jnp.ones((depth, feature_dim))\n",
    "        data_set = jnp.ones((num_samples, feature_dim))\n",
    "        labels = jnp.ones(num_samples)\n",
    "        m_phases = jnp.zeros_like(phases)\n",
    "        v_phases = jnp.zeros_like(phases)\n",
    "        m_weights = jnp.zeros_like(weights)\n",
    "        v_weights = jnp.zeros_like(weights)\n",
    "\n",
    "        init = (phases, data_set, labels, weights, m_phases, v_phases, m_weights, v_weights)\n",
    "\n",
    "        # FIX: The original train.py had a NameError.\n",
    "        # The source file is corrected to call optimiser.adam_step.\n",
    "        final_carry, loss_history = train.train(init)\n",
    "\n",
    "        self.assertEqual(len(final_carry), 8)\n",
    "        self.assertEqual(loss_history.shape, (globals.num_steps, 2))\n",
    "\n",
    "run_test(TestTrain, 'test_train_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_code(train.train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
